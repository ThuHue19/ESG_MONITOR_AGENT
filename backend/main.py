from fastapi import FastAPI, Request
from pydantic import BaseModel
from typing import List
from fastapi.middleware.cors import CORSMiddleware
from fetch_news import fetch_news
from analyze_news import analyze_article, summarize_overall, extract_keywords_from_question_gemini, markdown_to_plain_text
import os
import requests
import pandas as pd
import re
import numpy as np

app = FastAPI()

# CORS middleware ƒë·ªÉ frontend React c√≥ th·ªÉ g·ªçi API
app.add_middleware(
    CORSMiddleware,
    origins = [
    "https://esg-monitor-agent-website.onrender.com",  # domain frontend c·ªßa b·∫°n
    "http://localhost:3000",  # n·∫øu ch·∫°y local frontend
],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

FINNHUB_API_KEY = "d1qsvrhr01qo4qd99jkgd1qsvrhr01qo4qd99jl0"

# Load ESG data t·ª´ file CSV
ESG_DATA_PATH = "data.csv"
try:
    esg_df = pd.read_csv(ESG_DATA_PATH)
    esg_df['ticker'] = esg_df['ticker'].str.upper()  # Chu·∫©n h√≥a c·ªôt ticker
    print("Columns in data.csv:", esg_df.columns.tolist())  # Debug: In danh s√°ch c·ªôt
except Exception as e:
    print(f"Failed to load ESG data: {e}")
    esg_df = pd.DataFrame()

class CompanyRequest(BaseModel):
    companies: List[str]

class ArticleAnalysis(BaseModel):
    title: str
    url: str
    analysis: str

class CompanyAnalysisResponse(BaseModel):
    company: str
    articles: List[ArticleAnalysis]
    overall_summary: str

class AskRequest(BaseModel):
    question: str

class QuestionAnswerResponse(BaseModel):
    question: str
    summary: str
    articles: List[ArticleAnalysis]

class ESGRequest(BaseModel):
    symbol: str

@app.post("/api/search_query")
async def search_query(request: AskRequest):
    question = request.question
    print(f"Received question: {question}")  # Debug

    # G·ªçi Gemini ƒë·ªÉ tr√≠ch xu·∫•t t·ª´ kh√≥a
    response = extract_keywords_from_question_gemini(question)
    print("Gemini raw response:", response)

    # Tr√≠ch xu·∫•t d√≤ng ch·ª©a t·ª´ kh√≥a
    match = re.search(r"- Keywords:\s*(.*?)(?:\n|$)", response, re.DOTALL)
    if match:
        keyword_line = match.group(1)
        keywords = [kw.strip().lower() for kw in keyword_line.split(",") if kw.strip()]
    else:
        keywords = [response.strip().lower()]  # Fallback: s·ª≠ d·ª•ng to√†n b·ªô response
    print(f"‚úÖ Extracted keywords: {keywords}")

    # Ki·ªÉm tra c·ªôt 'name' trong DataFrame
    if 'name' not in esg_df.columns:
        print("Error: 'name' column not found in data.csv")
        return {"error": "Invalid data format: 'name' column missing in ESG data"}

    # Danh s√°ch t√™n c√¥ng ty chu·∫©n h√≥a t·ª´ d·ªØ li·ªáu
    company_names_in_data = [c.lower().strip() for c in esg_df['name'].tolist()]
    print(f"Company names in data: {company_names_in_data}")

    # T√¨m t·ª´ kh√≥a n√†o kh·ªõp v·ªõi t√™n c√¥ng ty
    matched_companies = []
    for kw in keywords:
        for company_name in company_names_in_data:
            if kw in company_name or company_name in kw:
                matched_companies.append(company_name)
    matched_companies = list(set(matched_companies))  # Lo·∫°i b·ªè tr√πng l·∫∑p

    if matched_companies:
        company_name = matched_companies[0]
    else:
        company_name = keywords[0] if keywords else "Unknown"
    print(f"üîç Matched company: {company_name}")

    # T·∫°o map t√™n c√¥ng ty ‚Üí ticker
    companyToTicker = {row['name'].lower().strip(): row['ticker'] for _, row in esg_df.iterrows()}
    print(f"companyToTicker: {companyToTicker}")

    # L·∫•y ticker n·∫øu c√≥
    ticker = companyToTicker.get(company_name.lower().strip())
    print(f"Found ticker: {ticker}")

    if ticker:
        esg_data = esg_df[esg_df["ticker"].str.upper() == ticker.upper()]
        if not esg_data.empty:
            row = esg_data.iloc[0]
            # Chuy·ªÉn ƒë·ªïi numpy.int64 sang int ƒë·ªÉ tr√°nh l·ªói JSON serialization
            return {
                "ticker": ticker,
                "company": row["name"],
                "environment_score": int(row["environment_score"]) if pd.notnull(row["environment_score"]) else None,
                "social_score": int(row["social_score"]) if pd.notnull(row["social_score"]) else None,
                "governance_score": int(row["governance_score"]) if pd.notnull(row["governance_score"]) else None,
                "total_score": int(row["total_score"]) if pd.notnull(row["total_score"]) else None,
                "environment_grade": row["environment_grade"],
                "social_grade": row["social_grade"],
                "governance_grade": row["governance_grade"],
                "total_grade": row["total_grade"]
            }

    return {
        "error": f"No ESG data found for company '{company_name}'. This may be due to limited public ESG disclosures, common for smaller companies in emerging markets like China's education sector."
    }

@app.post("/api/finnhub_esg")
async def finnhub_esg(request: ESGRequest):
    symbol = request.symbol.upper()
    esg_data = esg_df[esg_df["ticker"].str.upper() == symbol]
    if not esg_data.empty:
        row = esg_data.iloc[0]
        # Chuy·ªÉn ƒë·ªïi numpy.int64 sang int
        return {
            "ticker": symbol,
            "company": row["name"],
            "environment_score": int(row["environment_score"]) if pd.notnull(row["environment_score"]) else None,
            "social_score": int(row["social_score"]) if pd.notnull(row["social_score"]) else None,
            "governance_score": int(row["governance_score"]) if pd.notnull(row["governance_score"]) else None,
            "total_score": int(row["total_score"]) if pd.notnull(row["total_score"]) else None,
            "environment_grade": row["environment_grade"],
            "social_grade": row["social_grade"],
            "governance_grade": row["governance_grade"],
            "total_grade": row["total_grade"]
        }
    return {
        "error": f"No ESG data found for ticker '{symbol}'. This may be due to limited public ESG disclosures."
    }

def analyze_company_esg(company: str) -> CompanyAnalysisResponse:
    articles = fetch_news(company, limit=5)
    if not articles:
        return CompanyAnalysisResponse(
            company=company,
            articles=[],
            overall_summary=f"No articles found for {company}. This may be due to limited news coverage."
        )

    analyzed_articles = []
    analyses = []
    for article in articles:
        analysis = analyze_article(article['title'], article['content'], company)
        analyses.append(analysis)
        analyzed_articles.append(
            ArticleAnalysis(
                title=article['title'],
                url=article['url'],
                analysis=analysis
            )
        )

    overall_summary = summarize_overall(company, analyses)
    return CompanyAnalysisResponse(
        company=company,
        articles=analyzed_articles,
        overall_summary=overall_summary
    )

@app.post("/api/analyze_companies", response_model=List[CompanyAnalysisResponse])
async def analyze_companies_api(request: CompanyRequest):
    results = []
    for company in request.companies:
        result = analyze_company_esg(company)
        results.append(result)
    return results

@app.get("/api/analyze_default_companies", response_model=List[CompanyAnalysisResponse])
async def analyze_default_companies():
    try:
        with open("company_list.txt", "r") as f:
            companies = [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        return []

    results = []
    for company in companies:
        result = analyze_company_esg(company)
        results.append(result)
    return results

@app.post("/api/ask", response_model=QuestionAnswerResponse)
async def ask_ai(request: AskRequest):
    question = request.question
    response = extract_keywords_from_question_gemini(question)
    print("üîç Gemini response for /api/ask:", response)

    # Tr√≠ch xu·∫•t t·ª´ kh√≥a
    match = re.search(r"- Keywords:\s*(.*?)(?:\n|$)", response, re.DOTALL)
    if match:
        keyword_line = match.group(1)
        keywords = [kw.strip().lower() for kw in keyword_line.split(",") if kw.strip()]
    else:
        keywords = [response.strip().lower()]
    print(f"‚úÖ Extracted keywords for /api/ask: {keywords}")

    all_articles = []
    for keyword in keywords:
        articles = fetch_news(keyword)
        for article in articles:
            analysis = analyze_article(article['title'], article['content'])
            all_articles.append({
                "title": article['title'],
                "url": article['url'],
                "analysis": analysis
            })

    def relevance_score(article):
        return sum(kw.lower() in article['title'].lower() for kw in keywords)

    sorted_articles = sorted(all_articles, key=relevance_score, reverse=True)
    overall_summary = summarize_overall(question, [a["analysis"] for a in sorted_articles])

    return QuestionAnswerResponse(
        question=question,
        summary=overall_summary,
        articles=[ArticleAnalysis(**a) for a in sorted_articles]
    )